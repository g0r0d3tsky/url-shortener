version: '3.1'
services:
#  url_service:
#    build:
#      context:    ./url-service
#      dockerfile: Dockerfile
#    ports:
#      - "8080:8080"
#    env_file:
#      - url-service/cmd/api/v1/.env
#    depends_on:
#      - zoo1
#      - kafka1
#      - postgres
#      - redis
#    networks:
#      - internal
#
#  storage_service:
#      build:
#        context: ./storage-service
#        dockerfile: Dockerfile
#      env_file:
#        - storage-service/cmd/.env
#      depends_on:
#        - zoo1
#        - kafka1
#        - postgres
#        - redis
#        - url_service
#      networks:
#        - internal
#
#  cleaner_service:
#    build:
#      context: ./cleaner-service
#      dockerfile: Dockerfile
#    env_file:
#      - cleaner-service/cmd/.env
#    depends_on:
#      - postgres
#      - zoo1
#      - kafka1
#      - redis
#      - url_service
#    networks:
#      - internal

  postgres:
    container_name: url_db
    image: postgres:latest
    ports:
      - 5432:5432
    user: postgres
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
    volumes:
      - /var/lib/postgresql/data:/var/lib/postgresql/data
    healthcheck:
        test: [ "CMD-SHELL", "pg_isready" ]
        interval: 10s
        timeout: 5s
        retries: 5
    networks:
      - internal

  zoo1:
    image: confluentinc/cp-zookeeper:7.3.2
    hostname: zoo1
    container_name: zoo-url
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_SERVERS: zoo1:2888:3888
    networks:
      - internal

  kafka1:
    image: confluentinc/cp-kafka:7.3.2
    hostname: kafka1
    container_name: kafka1-url
    ports:
      - "9092:9092"
      - "29092:29092"
      - "9999:9999"
    environment:
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka1:19092,EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9092,DOCKER://host.docker.internal:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,DOCKER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: "zoo1:2181"
      KAFKA_BROKER_ID: 1
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_JMX_PORT: 9999
      KAFKA_JMX_HOSTNAME: ${DOCKER_HOST_IP:-127.0.0.1}
      KAFKA_AUTHORIZER_CLASS_NAME: kafka.security.authorizer.AclAuthorizer
      KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "true"
    healthcheck:
      test: kafka-topics --bootstrap-server kafka1:9092 --list
      interval: 30s
      timeout: 10s
      retries: 3

    depends_on:
      - zoo1
    networks:
      - internal

  redis:
    image: redis
    ports:
      - 6379:6379
    command: redis-server --save 20 1 --loglevel warning
    healthcheck:
      test: [ "CMD", "redis-cli", "ping" ]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - internal

  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "19090:9090"

  grafana:
    image: grafana/grafana-oss:9.4.3
    ports:
      - "13000:3000"
    volumes:
      - grafana-data:/var/lib/grafana

networks:
  internal:

volumes:
  grafana-data:
